{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import sys\n",
    "import string\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import arff\n",
    "from operator import itemgetter\n",
    "from scipy.stats import randint as sp_randint\n",
    "from time import time\n",
    "import random\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.grid_search import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn import linear_model\n",
    "from sklearn.externals.six import StringIO\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from IPython.core.display import Image\n",
    "\n",
    "import pydot\n",
    "\n",
    "from plot_learning_curve import plot_learning_curve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Training Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of examples: 2709\n",
      "Features:  ['gender', 'Firgen', 'famincome', 'SATCRDG', 'SATMATH', 'SATWRTG', 'SATTotal', 'HSGPA', 'ACTRead', 'ACTMath', 'ACTEngWrit', 'APIScore', 'FirstLang', 'HSGPAunweighted']\n",
      "Wall time: 106 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "gender = {'Male' : 0, 'Female' : 1, 'Unknown' : 2}\n",
    "language = {'English' : 0, 'EnglishandAnother' : 1, 'Another' : 2}\n",
    "\n",
    "trainfile = 'sample_data\\\\train_subj_norm.arff'\n",
    "\n",
    "x_train = []\n",
    "x_trainSubnum = []\n",
    "features = []\n",
    "y_train = []\n",
    "\n",
    "with open(trainfile, 'rb') as af:\n",
    "    arffFile = arff.load(af)\n",
    "    # do not include college gpa, college credits and subject number\n",
    "    features = [arffFile['attributes'][1:-3][i][0].encode(\"ascii\") for i in range(len(arffFile['attributes'][1:-3]))]\n",
    "    data = arffFile['data']\n",
    "    for row in data:\n",
    "        row[1] = gender[row[1]] # index of gender\n",
    "        row[13] = language[row[13]] # index of language\n",
    "        x_trainSubnum.append(row[0]) # sepporate subject number\n",
    "        x_train.append(row[1:-3]) # do not include number of credits taken first year\n",
    "        y_train.append(row[-1])\n",
    "        \n",
    "print 'Number of examples:', len(x_train)\n",
    "print 'Features: ', features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10-Fold Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.81 (+/- 0.04)\n",
      "Wall time: 32.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "rfc = RandomForestClassifier(n_estimators=1000)\n",
    "scores = cross_val_score(rfc, x_train, y_train, cv=10)\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fit RandomForests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=1000, n_jobs=1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False)\n",
      "Wall time: 3.36 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "rfc = RandomForestClassifier(n_estimators=1000)\n",
    "rfc.fit(x_train, y_train)\n",
    "print rfc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of examples: 46\n",
      "Wall time: 4 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "testfile = 'sample_data\\\\test_subj_norm.arff'\n",
    "\n",
    "x_test = []\n",
    "x_testSubnum = []\n",
    "y_test = []\n",
    "\n",
    "with open(testfile, 'rb') as af:\n",
    "    arffFile = arff.load(af)\n",
    "    # do not include college gpa, college credits and subject number\n",
    "    data = arffFile['data']\n",
    "    for row in data:\n",
    "        row[1] = gender[row[1]] # index of gender\n",
    "        row[13] = language[row[13]] # index of language\n",
    "        x_testSubnum.append(row[0]) # sepporate subject number\n",
    "        x_test.append(row[1:-3]) # do not include number of credits taken first year\n",
    "        y_test.append(row[-1])\n",
    "        \n",
    "print 'Number of examples:', len(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correctly Classified: 38\n",
      "Incorrectly Classified: 8\n",
      "Correct: 0.826087\n",
      "Error: 0.173913\n",
      "Wall time: 1.48 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "def calcError(model, X, Y, printWrong=False):\n",
    "    numCorrect = 0\n",
    "    numIncorrect = 0\n",
    "    incorrectList = []\n",
    "    testCount = len(X)\n",
    "    for index in range(testCount):\n",
    "        x = X[index]\n",
    "        prediction = model.predict(x)\n",
    "        if prediction == Y[index]:\n",
    "            numCorrect += 1\n",
    "        else:\n",
    "            numIncorrect += 1\n",
    "            if printWrong:\n",
    "                incorrectList.append((x_testSubnum[index], prediction, Y[index]))\n",
    "    print 'Correctly Classified:', numCorrect\n",
    "    print 'Incorrectly Classified:', numIncorrect\n",
    "    print 'Correct: %f' % (float(numCorrect) / float(testCount))\n",
    "    print 'Error: %f' % (1 - float(numCorrect) / float(testCount))\n",
    "    if printWrong:\n",
    "        print '====Incorrect Subjects===='\n",
    "        # Print incorrect examples\n",
    "        for x in incorrectList:\n",
    "            print 'Incorrect Sub. %d, Prediction: %s, Correct Label: %s' % (x)\n",
    "        print '=========================='\n",
    "\n",
    "calcError(rfc, x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perform Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Utility function to report best scores\n",
    "def report(grid_scores, n_top=3):\n",
    "    top_scores = sorted(grid_scores, key=itemgetter(1), reverse=True)[:n_top]\n",
    "    for i, score in enumerate(top_scores):\n",
    "        print(\"Model with rank: {0}\".format(i + 1))\n",
    "        print(\"Mean validation score: {0:.3f} (std: {1:.3f})\".format(\n",
    "              score.mean_validation_score,\n",
    "              np.std(score.cv_validation_scores)))\n",
    "        print(\"Parameters: {0}\".format(score.parameters))\n",
    "        print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomizedSearchCV took 5.78 seconds for 20 candidates parameter settings.\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.815 (std: 0.015)\n",
      "Parameters: {'bootstrap': True, 'min_samples_leaf': 7, 'min_samples_split': 9, 'criterion': 'gini', 'max_features': 4, 'max_depth': None}\n",
      "\n",
      "Model with rank: 2\n",
      "Mean validation score: 0.813 (std: 0.014)\n",
      "Parameters: {'bootstrap': False, 'min_samples_leaf': 2, 'min_samples_split': 8, 'criterion': 'gini', 'max_features': 4, 'max_depth': None}\n",
      "\n",
      "Model with rank: 3\n",
      "Mean validation score: 0.808 (std: 0.011)\n",
      "Parameters: {'bootstrap': True, 'min_samples_leaf': 4, 'min_samples_split': 4, 'criterion': 'entropy', 'max_features': 5, 'max_depth': None}\n",
      "\n",
      "Wall time: 5.78 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "clf = RandomForestClassifier(n_estimators=30)\n",
    "\n",
    "# specify parameters and distributions to sample from\n",
    "param_dist = {\"max_depth\": [3, None],\n",
    "              \"max_features\": sp_randint(1, 11),\n",
    "              \"min_samples_split\": sp_randint(1, 11),\n",
    "              \"min_samples_leaf\": sp_randint(1, 11),\n",
    "              #\"n_estimators\": [10,20,30,40,50],\n",
    "              \"bootstrap\": [True, False],\n",
    "              \"criterion\": [\"gini\", \"entropy\"]}\n",
    "\n",
    "# run randomized search\n",
    "n_iter_search = 20\n",
    "random_search = RandomizedSearchCV(clf, param_distributions=param_dist,\n",
    "                                   n_iter=n_iter_search)\n",
    "start = time()\n",
    "random_search.fit(x_train, y_train)\n",
    "print(\"RandomizedSearchCV took %.2f seconds for %d candidates\"\n",
    "      \" parameter settings.\" % ((time() - start), n_iter_search))\n",
    "report(random_search.grid_scores_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GridSearchCV took 52.47 seconds for 108 candidate parameter settings.\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.814 (std: 0.012)\n",
      "Parameters: {'bootstrap': False, 'min_samples_leaf': 5, 'min_samples_split': 5, 'criterion': 'gini', 'max_features': 5, 'max_depth': None}\n",
      "\n",
      "Model with rank: 2\n",
      "Mean validation score: 0.814 (std: 0.016)\n",
      "Parameters: {'bootstrap': False, 'min_samples_leaf': 10, 'min_samples_split': 5, 'criterion': 'gini', 'max_features': 5, 'max_depth': None}\n",
      "\n",
      "Model with rank: 3\n",
      "Mean validation score: 0.813 (std: 0.011)\n",
      "Parameters: {'bootstrap': True, 'min_samples_leaf': 5, 'min_samples_split': 10, 'criterion': 'gini', 'max_features': 5, 'max_depth': None}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# use a full grid over all parameters\n",
    "param_grid = {\"max_depth\": [None],\n",
    "              \"max_features\": [1, 5, len(features)],\n",
    "              \"min_samples_split\": [1, 5, 10],\n",
    "              \"min_samples_leaf\": [1, 5, 10],\n",
    "              #\"n_estimators\": [10,20,30,40,50],\n",
    "              \"bootstrap\": [True, False],\n",
    "              \"criterion\": [\"gini\", \"entropy\"]}\n",
    "\n",
    "# run grid search\n",
    "grid_search = GridSearchCV(clf, param_grid=param_grid)\n",
    "start = time()\n",
    "grid_search.fit(x_train, y_train)\n",
    "\n",
    "print(\"GridSearchCV took %.2f seconds for %d candidate parameter settings.\"\n",
    "      % (time() - start, len(grid_search.grid_scores_)))\n",
    "report(grid_search.grid_scores_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing on another Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of Training Set: 2302\n",
      "Length of Test Set: 407\n",
      "Correctly Classified: 337\n",
      "Incorrectly Classified: 70\n",
      "Correct: 0.828010\n",
      "Error: 0.171990\n",
      "Wall time: 16.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "xtrain, xtest, ytrain, ytest = train_test_split(x_train, y_train, test_size=0.1, random_state=0)\n",
    "print \"Length of Training Set:\", len(xtrain)\n",
    "print \"Length of Test Set:\", len(xtest)\n",
    "rfc = RandomForestClassifier(n_estimators=1000)\n",
    "rfc.fit(xtrain, ytrain)\n",
    "calcError(rfc, xtest, ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correctly Classified: 40\n",
      "Incorrectly Classified: 6\n",
      "Correct: 0.869565\n",
      "Error: 0.130435\n",
      "Wall time: 57 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "calcError(random_search, x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correctly Classified: 39\n",
      "Incorrectly Classified: 7\n",
      "Correct: 0.847826\n",
      "Error: 0.152174\n",
      "Wall time: 58 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "calcError(grid_search.best_estimator_, x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
